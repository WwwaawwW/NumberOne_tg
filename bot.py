import logging
import asyncio
from datetime import datetime
from aiogram import Bot, Dispatcher, types, F
from aiogram.enums import ParseMode
from aiogram.types import Message
from aiogram.fsm.storage.memory import MemoryStorage
from dotenv import load_dotenv
import os
import openai

load_dotenv()

TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TOKEN:
    raise ValueError("‚ùå BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω. –î–æ–±–∞–≤—å –µ–≥–æ –≤ Railway Variables –∏–ª–∏ .env")

if not OPENAI_API_KEY:
    raise ValueError("‚ùå OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω. –î–æ–±–∞–≤—å –µ–≥–æ –≤ Railway Variables –∏–ª–∏ .env")

openai.api_key = OPENAI_API_KEY

bot = Bot(token=TOKEN, parse_mode=ParseMode.HTML)
dp = Dispatcher(storage=MemoryStorage())

model_descriptions = {
    "gpt-3.5-turbo": "ü§ñ GPT-3.5 Turbo ‚Äî –±—ã—Å—Ç—Ä—ã–π –∏ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π.",
    "gpt-4": "üöÄ GPT-4 ‚Äî —Å–∫–æ—Ä–æ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –ø–æ–¥–ø–∏—Å–∫–µ.",
}

user_model = {}
user_gpt4_usage = {}
user_last_reset = {}

@dp.message(F.text == "/start")
async def cmd_start(message: types.Message):
    user_id = message.from_user.id
    user_model[user_id] = "gpt-3.5-turbo"
    user_gpt4_usage[user_id] = 0
    user_last_reset[user_id] = datetime.now()
    await message.answer(
        """üëã –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ NUMBER ONE ‚Äî –º–∏—Ä –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π!

üìå GPT-3.5 ‚Äî –±–µ—Å–ø–ª–∞—Ç–Ω–æ
üöÄ GPT-4, DALL¬∑E –∏ –ø—Ä–æ—á–µ–µ ‚Äî –ø–æ–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω—ã –∏–ª–∏ –ø–æ–¥ –ø–æ–¥–ø–∏—Å–∫—É."""
    )

@dp.message(F.text == "üß† –ù–∞—à–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (–æ–ø–∏—Å–∞–Ω–∏–µ)")
async def show_models(message: types.Message):
    text = "üß† <b>–î–æ—Å—Ç—É–ø–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:</b>\n\n"
    for desc in model_descriptions.values():
        text += f"{desc}\n"
    await message.answer(text, parse_mode="HTML")

@dp.message()
async def handle_message(message: Message):
    user_id = message.from_user.id
    model = user_model.get(user_id, "gpt-3.5-turbo")
    prompt = message.text

    try:
        response = openai.ChatCompletion.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        reply = response["choices"][0]["message"]["content"]
        await message.answer(reply)

    except openai.error.OpenAIError as e:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –æ—à–∏–±–∫—É –æ—Ç OpenAI
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞ OpenAI:\n<code>{str(e)}</code>", parse_mode="HTML")
        print(f"OpenAI API Error: {e}")

    except Exception as e:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ—á–∏–µ –æ—à–∏–±–∫–∏
        await message.answer(f"‚ö†Ô∏è –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞:\n<code>{str(e)}</code>", parse_mode="HTML")
        print(f"Unexpected Error: {e}")


async def main():
    logging.basicConfig(level=logging.INFO)
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
