import logging
import asyncio
from datetime import datetime
from aiogram import Bot, Dispatcher, types, F
from aiogram.enums import ParseMode
from aiogram.types import Message
from aiogram.fsm.storage.memory import MemoryStorage
from dotenv import load_dotenv
import os
from openai import OpenAI

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env
load_dotenv()

TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TOKEN:
    raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")

if not OPENAI_API_KEY:
    raise ValueError("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤
bot = Bot(token=TOKEN, parse_mode=ParseMode.HTML)
dp = Dispatcher(storage=MemoryStorage())
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# –°–ª–æ–≤–∞—Ä–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
user_model = {}
user_gpt4_usage = {}
user_last_reset = {}

# –û–ø–∏—Å–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
model_descriptions = {
    "gpt-3.5-turbo": "ü§ñ GPT-3.5 Turbo ‚Äî –±—ã—Å—Ç—Ä—ã–π –∏ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π.",
    "gpt-4": "üöÄ GPT-4 ‚Äî —Å–∫–æ—Ä–æ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –ø–æ–¥–ø–∏—Å–∫–µ.",
}

@dp.message(F.text == "/start")
async def cmd_start(message: types.Message):
    user_id = message.from_user.id
    user_model[user_id] = "gpt-3.5-turbo"
    user_gpt4_usage[user_id] = 0
    user_last_reset[user_id] = datetime.now()
    await message.answer(
        """üëã –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ NUMBER ONE ‚Äî –º–∏—Ä –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π!

üìå GPT-3.5 ‚Äî –±–µ—Å–ø–ª–∞—Ç–Ω–æ
üöÄ GPT-4, DALL¬∑E –∏ –ø—Ä–æ—á–µ–µ ‚Äî –ø–æ–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω—ã –∏–ª–∏ –ø–æ–¥ –ø–æ–¥–ø–∏—Å–∫—É."""
    )

@dp.message(F.text == "üß† –ù–∞—à–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (–æ–ø–∏—Å–∞–Ω–∏–µ)")
async def show_models(message: types.Message):
    text = "üß† <b>–î–æ—Å—Ç—É–ø–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:</b>\n\n"
    for desc in model_descriptions.values():
        text += f"{desc}\n"
    await message.answer(text, parse_mode="HTML")

@dp.message(F.text)
async def handle_message(message: Message):
    prompt = message.text
    model = "gpt-3.5-turbo"
    await message.answer("‚öôÔ∏è –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç –æ—Ç GPT-3.5...")

    try:
        response = openai_client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        reply = response.choices[0].message.content
        await message.answer(reply)

    except Exception as e:
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞ OpenAI:\n<code>{str(e)}</code>", parse_mode="HTML")
        print("OpenAI Error:", e)

async def main():
    logging.basicConfig(level=logging.INFO)
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
